{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('./data/sessions.json', 'r') as f:\n",
    "    sessions = json.load(f)\n",
    "\n",
    "sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.schema import Document\n",
    "\n",
    "documents = []\n",
    "for session in sessions:\n",
    "    doc = Document(\n",
    "        page_content = session['abstract'],\n",
    "        metadata = {\n",
    "            'title': session['title'],\n",
    "            'speakers': session['speakers'],\n",
    "            'room': session['room'],\n",
    "            'start_time': session['start_time'],\n",
    "            'end_time': session['end_time']\n",
    "        }\n",
    "    )\n",
    "    documents.append(doc)\n",
    "\n",
    "embeddings = OpenAIEmbeddings()\n",
    "vector_store = FAISS.from_documents(documents, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI  \n",
    "\n",
    "\n",
    "llm = ChatOpenAI(  \n",
    "  model=\"gpt-4o\",  \n",
    "  temperature=0.7\n",
    ")\n",
    "\n",
    "template = \"\"\"\n",
    "You are a helpful assistant helping attendees at Nebraska.Code(), \n",
    "a software development conference, make the most of their conference \n",
    "by answering questions about sessions and helping them find the best \n",
    "sessions to attend based on their interests. Your answers should be \n",
    "conversational - do not simply respond with the verbatim session data, \n",
    "but do make sure to include relevant information such as the room and \n",
    "times of the sessions. If there is more than one session that matches \n",
    "their query, feel free to reference them all. A bulleted list is \n",
    "acceptable in the output.\n",
    "\n",
    "Here are some sessions that appear relevant to the user's question. \n",
    "Use these as you see fit to help answer the user's question:\n",
    "\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "Answer: \n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "  template=template, \n",
    "  input_variables=[\"context\", \"question\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"What sessions about unit testing should I go to?\"\n",
    "llm.invoke(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vector_store.as_retriever(search_kwargs={'k': 10})\n",
    "docs = retriever.invoke(question)\n",
    "\n",
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = prompt.invoke({\"context\": docs, \"question\": question })\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = llm.invoke(p)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "\n",
    "chain = (\n",
    "  {\"context\": vector_store.as_retriever(search_kwargs={'k': 10}),  \"question\": RunnablePassthrough()} \n",
    "  | prompt \n",
    "  | llm\n",
    "  | StrOutputParser() \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(chain.invoke(question))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
